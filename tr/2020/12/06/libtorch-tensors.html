<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">

    <!-- JQuery (used for bootstrap and jekyll search) -->
    <script src="/assets/js/jquery-3.2.1.min.js" ></script>

    <!-- Main JS (navbar.js and katex_init.js)-->
    <script defer=true src="/assets/js/main.min.js"></script>

    <!-- CSS -->
    <link rel="stylesheet" href="/tr/assets/css/main.css">

    <!--Favicon-->
    <link rel="shortcut icon" href="/tr/assets/favicon.ico" type="image/x-icon">

    <!-- Canonical -->
    <link rel="canonical" href="https://blgnksy.github.io/tr/2020/12/06/libtorch-tensors.html">

    <!-- RSS -->
    <link rel="alternate" type="application/atom+xml" title="NDeep" href="https://blgnksy.github.io/tr///feed.xml"/>

    <!-- Font Awesome -->
    <!-- <link href="/tr//maxcdn.bootstrapcdn.com/font-awesome/4.7.0/css/font-awesome.min.css" rel="stylesheet"> -->
    <link rel="stylesheet" type="text/css" href="/tr/assets/css/font-awesome.min.css">

    <!-- Google Fonts -->
    
    <link href="/tr//fonts.googleapis.com/css?family=Source+Sans+Pro:400,700,700italic,400italic" rel="stylesheet" type="text/css">
    

    <!-- KaTeX 0.8.3 -->
    
    <!--<link rel="stylesheet" href="/tr//cdnjs.cloudflare.com/ajax/libs/KaTeX/0.8.3/katex.min.css">
    <script src="//cdnjs.cloudflare.com/ajax/libs/KaTeX/0.8.3/katex.min.js"></script> -->
    <link rel="stylesheet" type="text/css" href="/tr/assets/css/katex.min.css">
    <script src="/assets/js/katex.min.js">
    </script>
    


    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-NWPYEC2Z49"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'G-NWPYEC2Z49');
    </script>


    <!-- Google Analytics -->
    
    <script>
        (function(i, s, o, g, r, a, m) {
            i['GoogleAnalyticsObject'] = r;
            i[r] = i[r] || function() {
                (i[r].q = i[r].q || []).push(arguments)
            }, i[r].l = 1 * new Date();
            a = s.createElement(o),
                m = s.getElementsByTagName(o)[0];
            a.async = 1;
            a.src = g;
            m.parentNode.insertBefore(a, m)
        })(window, document, 'script', '//www.google-analytics.com/analytics.js', 'ga');

        ga('create', 'G-NWPYEC2Z49', 'auto');
        ga('send', 'pageview');

    </script>
    

    <!-- seo tags -->
    <!-- Begin Jekyll SEO tag v2.8.0 -->
<title>C++ Derin Öğrenme-2 Pytorch C++ API LibTorch Tensör İşlemleri | Blog About Deep/Machine Learning, CUDA, Computer Vision</title>
<meta name="generator" content="Jekyll v3.10.0" />
<meta property="og:title" content="C++ Derin Öğrenme-2 Pytorch C++ API LibTorch Tensör İşlemleri" />
<meta property="og:locale" content="tr" />
<meta name="description" content="Yazı dizisinin bu yazısında LibTorch‘da tensörlerin nasıl oluşturulduğunu, erişildiğini ve değiştirildiğini açıklayacağım. LibTorch‘un ne olduğunu, neler yapılabildiğini açıkladığım giriş niteliğindeki yazıyı okumadıysanız o yazıdan başlamanızı tavsiye ederim. Bu noktada bu yazı çok daha uzun olabilirdi ama olabilen tüm sadeliği ama yeterli bilgiyi sağlayacak şekilde süzüldüğünü ve ana referansın dokümantasyonun kendisi olduğunu unutmayın." />
<meta property="og:description" content="Yazı dizisinin bu yazısında LibTorch‘da tensörlerin nasıl oluşturulduğunu, erişildiğini ve değiştirildiğini açıklayacağım. LibTorch‘un ne olduğunu, neler yapılabildiğini açıkladığım giriş niteliğindeki yazıyı okumadıysanız o yazıdan başlamanızı tavsiye ederim. Bu noktada bu yazı çok daha uzun olabilirdi ama olabilen tüm sadeliği ama yeterli bilgiyi sağlayacak şekilde süzüldüğünü ve ana referansın dokümantasyonun kendisi olduğunu unutmayın." />
<link rel="canonical" href="https://blgnksy.github.io/tr/2020/12/06/libtorch-tensors.html" />
<meta property="og:url" content="https://blgnksy.github.io/2020/12/06/libtorch-tensors.html" />
<meta property="og:site_name" content="Blog About Deep/Machine Learning, CUDA, Computer Vision" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2020-12-06T00:00:00+00:00" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:title" content="C++ Derin Öğrenme-2 Pytorch C++ API LibTorch Tensör İşlemleri" />
<script type="application/ld+json">
{"@context":"https://schema.org","@type":"BlogPosting","dateModified":"2020-12-06T00:00:00+00:00","datePublished":"2020-12-06T00:00:00+00:00","description":"Yazı dizisinin bu yazısında LibTorch‘da tensörlerin nasıl oluşturulduğunu, erişildiğini ve değiştirildiğini açıklayacağım. LibTorch‘un ne olduğunu, neler yapılabildiğini açıkladığım giriş niteliğindeki yazıyı okumadıysanız o yazıdan başlamanızı tavsiye ederim. Bu noktada bu yazı çok daha uzun olabilirdi ama olabilen tüm sadeliği ama yeterli bilgiyi sağlayacak şekilde süzüldüğünü ve ana referansın dokümantasyonun kendisi olduğunu unutmayın.","headline":"C++ Derin Öğrenme-2 Pytorch C++ API LibTorch Tensör İşlemleri","mainEntityOfPage":{"@type":"WebPage","@id":"https://blgnksy.github.io/2020/12/06/libtorch-tensors.html"},"url":"https://blgnksy.github.io/2020/12/06/libtorch-tensors.html"}</script>
<!-- End Jekyll SEO tag -->

    <!-- Manual seo tags -->
    <!--
    <title>C++ Derin Öğrenme-2 Pytorch C++ API LibTorch Tensör İşlemleri | NDeep</title>
    <meta name="description" content="Yazı dizisinin bu yazısında LibTorch‘da tensörlerin nasıl oluşturulduğunu, erişildiğini ve değiştirildiğini açıklayacağım. LibTorch‘un ne olduğunu, neler yap...">
    -->

    <!-- Structured Data -->
    <script type="application/ld+json">
    {
      "@context": "https://schema.org",
      "@type": "WebSite",
      "name": "NDeep",
      "url": "https://blgnksy.github.io",
      "description": "",
      "inLanguage": "tr",
      "potentialAction": {
        "@type": "SearchAction",
        "target": "https://blgnksy.github.io/search/?q={search_term_string}",
        "query-input": "required name=search_term_string"
      }
    }
    </script>
</head>

  <body>
    <header class="site-header">
    
    <!-- Logo and title -->
	<div class="branding">
		<a href="/tr/">
			<img class="avatar" src="/assets/img/triangle.svg" alt=""/>
		</a>

		<h1 class="site-title">
			<a href="/tr/">NDeep</a>
		</h1>
	</div>
    
    <!-- Toggle menu -->
    <nav class="clear">
    <a id="pull" class="toggle" href="#">
    <i class="fa fa-bars fa-lg"></i>
    </a>
    
    <!-- Menu -->
    <ul>
        
        
        
        
        <li class="separator">
            |
        </li>
        <li>
            <a class="clear" href="/tr/about/">
                Hakkımda
            </a>
        </li>
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
         
        
        
        <li class="separator">
            |
        </li>
        <li>
            <a class="clear" href="https://blgnksy.github.io/tr/search">
                <i class="fa fa-search" aria-hidden="true"></i>
            </a>
        </li>
        
        
        <li class="separator">
            |
        </li>
        <li>
            <a class="clear" href="https://blgnksy.github.io/tr/tags">
                <i class="fa fa-tags" aria-hidden="true"></i>
            </a>
        </li>
        
        
        
        
    </ul>
        
	</nav>
</header>

    <div class="content">
      <article >
  <header id="main" style="background-image: url('/')">
    <h1 id="C%2B%2B+Derin+%C3%96%C4%9Frenme-2+Pytorch+C%2B%2B+API+LibTorch+Tens%C3%B6r+%C4%B0%C5%9Flemleri" class="title">C++ Derin Öğrenme-2 Pytorch C++ API LibTorch Tensör İşlemleri</h1>
    <p class="meta">
    December 6, 2020
    
    </p>
  </header>
  <section class="post-content"><p>Yazı dizisinin bu yazısında <em>LibTorch</em>‘da tensörlerin nasıl oluşturulduğunu, erişildiğini ve değiştirildiğini açıklayacağım. <em>LibTorch</em>‘un ne olduğunu, neler yapılabildiğini açıkladığım giriş niteliğindeki yazıyı okumadıysanız <a href="https://blgnksy.github.io/tr/2020/12/03/libtorch-config.html">o yazıdan</a> başlamanızı tavsiye ederim. Bu noktada bu yazı çok daha uzun olabilirdi ama olabilen tüm sadeliği ama yeterli bilgiyi sağlayacak şekilde süzüldüğünü ve ana referansın dokümantasyonun kendisi olduğunu unutmayın.</p>

<p>ATen tensör kütüphanesi <em>PyTorch</em>‘un tensör işlemleri için  arka planda kullandığı kütüphanedir ve C++14 standartlarına uygun olarak yazılmıştır. Tensör tipleri dinamik olarak çözümlenmektedir. Sonuç olarak içinde tuttuğu veri tipi ne olursa olsun ya da CPU/GPU tensörü olursa olsun tek bir tensör arayüzü bizi karşılamaktadır. Tensör sınıfının arayüzünü <a href="https://pytorch.org/cppdocs/api/classat_1_1_tensor.html#exhale-class-classat-1-1-tensor">dokümantasyondan</a> inceleyebilirsiniz.</p>

<p>Tensörler üzerinde işlem yapan yüzlerce fonksiyon bulunmaktadır. Bu <a href="https://pytorch.org/cppdocs/api/namespace_at.html#functions">fonksiyonların listesine</a> bağlantıyı kullanarak ulaşabilirsiniz. Fonksiyon isimlendirmeleriyle ilgili olarak dikkatinizi çekmek istediğim bir nokta <code class="language-plaintext highlighter-rouge">_</code> karakteriyle biten fonksiyonlar tensör üzerinde değişiklik yapmaktadırlar yani bu fonksiyon çağrılırken tensör C++’da sol taraf referansı (lvalue reference) olarak aktarılmaktadır. Şimdi bu sınıfı kullanmaya başlayalım:</p>

<h1 id="1-tensör-oluşturma">1. Tensör Oluşturma:</h1>

<h2 id="11-fabrika-fonksiyonlarını-kullanma">1.1 Fabrika Fonksiyonlarını Kullanma</h2>

<p>Bu fonksiyonlar <em>Fabrika Tasarım Desenleri</em>nde olduğu gibi çalışıp sonuçta <code class="language-plaintext highlighter-rouge">torch::Tensor</code> geri döndüren fonksiyonlardır. Aslında bunlardan bir tanesini ilk <a href="https://blgnksy.github.io/tr/2020/12/03/libtorch-config.html">yazıda</a> kullanmıştım: <code class="language-plaintext highlighter-rouge">torch::rand()</code> fonksiyonu argüman olarak aldığı şekile göre bize tensör geri döndürmektedir. Bu fonksiyonlar:</p>

<ul>
  <li><a href="https://pytorch.org/docs/stable/torch.html#torch.arange">arange</a>: Sıralı tamsayılardan oluşan tensör geri döndürür,</li>
  <li><a href="https://pytorch.org/docs/stable/torch.html#torch.empty">empty</a>: İlk değer verilmemiş ,</li>
  <li><a href="https://pytorch.org/docs/stable/torch.html#torch.eye">eye</a>: Returns an identity matrix,</li>
  <li><a href="https://pytorch.org/docs/stable/torch.html#torch.full">full</a>: Returns a tensor filled with a single value,</li>
  <li><a href="https://pytorch.org/docs/stable/torch.html#torch.linspace">linspace</a>: Returns a tensor with values linearly spaced in some interval,</li>
  <li><a href="https://pytorch.org/docs/stable/torch.html#torch.logspace">logspace</a>: Returns a tensor with values logarithmically spaced in some interval,</li>
  <li><a href="https://pytorch.org/docs/stable/torch.html#torch.ones">ones</a>: Returns a tensor filled with all ones,</li>
  <li><a href="https://pytorch.org/docs/stable/torch.html#torch.rand">rand</a>: Returns a tensor filled with values drawn from a uniform distribution on <code class="language-plaintext highlighter-rouge">[0, 1)</code>.</li>
  <li><a href="https://pytorch.org/docs/stable/torch.html#torch.randint">randint</a>: Returns a tensor with integers randomly drawn from an interval,</li>
  <li><a href="https://pytorch.org/docs/stable/torch.html#torch.randn">randn</a>: Returns a tensor filled with values drawn from a unit normal distribution,</li>
  <li><a href="https://pytorch.org/docs/stable/torch.html#torch.randperm">randperm</a>: Returns a tensor filled with a random permutation of integers in some interval,</li>
  <li><a href="https://pytorch.org/docs/stable/torch.html#torch.zeros">zeros</a>: Returns a tensor filled with all zeros.</li>
</ul>

<p>Linkler <em>Python</em> dokümantasyonuna bağlantı vermektedir. C++ API’da ki işlevleri, parametreleri ve isimli argümanları aynıdır. İsimli argümanların <code class="language-plaintext highlighter-rouge">torch::TensorOptions</code> nesnesi vasıtasıyla tanımlanabildiğine, ulaşılabildiğine ve değiştirilebildiğine dikkat edin. Bunu birazdan <code class="language-plaintext highlighter-rouge">torch:rand()</code> fonksiyonunda ele alacağım ve diğer fonksiyonlarda da geçerli olacaklar.</p>

<p>Şimdi kullanışlı fabrika fonksiyonlarına yakından bakalım (Not: İlk fonksiyonu detaylı inceleyeceğim, diğerleri için dokümantasyonu kullanmanızı önereceğim. Çünkü API’lar hızlı değişime uğruyor ve senkron tutmak zahmetli olacaktır.):</p>

<h3 id="111-torchrand">1.1.1. <code class="language-plaintext highlighter-rouge">torch::rand()</code></h3>

<p>Bu fonksiyon <code class="language-plaintext highlighter-rouge">[0,1)</code> aralığında rastgele kayan noktalı sayılar üretir. Fonksiyonun protipine bakalım: <code class="language-plaintext highlighter-rouge">torch::rand(*size, *, out=None, dtype=None, layout=torch.strided, device=None, requires_grad=False) → Tensor</code>.</p>

<h4 id="parametreleri">Parametreleri</h4>

<ul>
  <li><strong>size</strong> (int): Tensörün şeklini belirlediğimiz parametredir. Tamsayı değerler alır.</li>
</ul>

<h4 id="i̇simli-argümanları">İsimli Argümanları</h4>

<ul>
  <li><strong>out</strong> (<a href="https://pytorch.org/docs/stable/tensors.html#torch.Tensor"><em>Tensor</em></a><em>,</em> <em>optional</em>) – Çıktı tensörü.</li>
  <li><strong>dtype</strong> (<a href="https://pytorch.org/docs/stable/tensor_attributes.html#torch.torch.dtype"><code class="language-plaintext highlighter-rouge">torch.dtype</code></a>, optional) – Tensör veri tipi.</li>
  <li><strong>layout</strong> (<a href="https://pytorch.org/docs/stable/tensor_attributes.html#torch.torch.layout"><code class="language-plaintext highlighter-rouge">torch.layout</code></a>, optional) – Tensörün bellekte tutulma yöntemi (<code class="language-plaintext highlighter-rouge">dense</code>/<code class="language-plaintext highlighter-rouge">strided</code>). Bu seçeneğin ileride ki versiyonlarda kaldırılması planlanmaktadır.</li>
  <li><strong>device</strong> (<a href="https://pytorch.org/docs/stable/tensor_attributes.html#torch.torch.device"><code class="language-plaintext highlighter-rouge">torch.device</code></a>, optional) – Tensörün hangi aygıtta saklanacağı (CPU/GPU).</li>
  <li><strong>requires_grad</strong> (<a href="https://docs.python.org/3/library/functions.html#bool"><em>bool</em></a><em>,</em> <em>optional</em>) – Geri döndürülen tensörün otomatik gradyan işlemine tabii olup olmayacağı.</li>
</ul>

<h4 id="kullanımı">Kullanımı:</h4>

<p>En basit kullanımı şekli verip tensörü kullanmaktır.</p>

<div class="language-c++ highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">torch</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">randTensor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">::</span><span class="n">rand</span><span class="p">(</span><span class="cm">/*size:*/</span><span class="p">{</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">});</span>
</code></pre></div></div>

<p>Bu kullanım ilk yazıdan hatırlarsanız şekli <code class="language-plaintext highlighter-rouge">2, 3</code> olan bir CPU tensörü geri döndürmüştü. Hatırlayacak olursak bu tensörü standart çıkış akımına yazdırırsak aşağıdaki çıktıyı alırız (çıktılardaki kayan noktalı sayıların rastgele olacağını unutmayın):</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code>0.6147  0.6752  0.8963
0.5627  0.4836  0.5589
<span class="o">[</span> CPUFloatType<span class="o">{</span>2,3<span class="o">}</span> <span class="o">]</span>
</code></pre></div></div>

<p>İsimli argümanların kullanımı için önce bu seçenekleri bir <code class="language-plaintext highlighter-rouge">torch::TensorOptions</code> nesnesi içerisinde tanımlamamız gerekiyor. <strong>Bu seçeneklerin diğer fabrika fonksiyonlarında da aynı şekilde kullanıldığını hatırlatıp</strong> alabilecekleri değerlere göz atalım:</p>

<ul>
  <li><code class="language-plaintext highlighter-rouge">dtype</code>: <code class="language-plaintext highlighter-rouge">kUInt8</code>, <code class="language-plaintext highlighter-rouge">kInt8</code>, <code class="language-plaintext highlighter-rouge">kInt16</code>, <code class="language-plaintext highlighter-rouge">kInt32</code>, <code class="language-plaintext highlighter-rouge">kInt64</code>, <code class="language-plaintext highlighter-rouge">kFloat32</code> ve <code class="language-plaintext highlighter-rouge">kFloat64</code>,</li>
  <li><code class="language-plaintext highlighter-rouge">layout</code>: <code class="language-plaintext highlighter-rouge">kStrided</code> ve <code class="language-plaintext highlighter-rouge">kSparse</code>,</li>
  <li><code class="language-plaintext highlighter-rouge">device</code>: <code class="language-plaintext highlighter-rouge">kCPU</code> ya da <code class="language-plaintext highlighter-rouge">kCUDA</code> (birden fazla GPU’nuz varsa aygıt indeksi de alır),</li>
  <li><code class="language-plaintext highlighter-rouge">requires_grad</code>: <code class="language-plaintext highlighter-rouge">true</code> ya da <code class="language-plaintext highlighter-rouge">false</code>.</li>
</ul>

<p>Şimdi seçenekleri kullanarak bir tensör oluşturalım. 32 bitlik kayan noktalı sayıları <code class="language-plaintext highlighter-rouge">strided</code> bellek yerleşiminde, 0 numaralı GPU’da otomatik gradyana dahil olacak bir tensör elde etmek için aşağıdaki kod öbeğini kullanabiliriz:</p>

<div class="language-c++ highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">auto</span> <span class="n">options</span> <span class="o">=</span> <span class="n">torch</span><span class="o">::</span><span class="n">TensorOptions</span><span class="p">()</span>
            <span class="p">.</span><span class="n">dtype</span><span class="p">(</span><span class="n">torch</span><span class="o">::</span><span class="n">kFloat32</span><span class="p">)</span>
            <span class="p">.</span><span class="n">layout</span><span class="p">(</span><span class="n">torch</span><span class="o">::</span><span class="n">kStrided</span><span class="p">)</span>
            <span class="p">.</span><span class="n">device</span><span class="p">(</span><span class="n">torch</span><span class="o">::</span><span class="n">kCUDA</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
            <span class="p">.</span><span class="n">requires_grad</span><span class="p">(</span><span class="nb">true</span><span class="p">);</span>

<span class="n">torch</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">randTensor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">::</span><span class="n">rand</span><span class="p">(</span><span class="cm">/*size:*/</span><span class="p">{</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">},</span> <span class="n">options</span><span class="p">);</span>
</code></pre></div></div>

<p>Bu seçeneklerden bir veya birkaçını doğrudan fonksiyon olarak da kullanabilirsiniz. Bu fonksiyonlar bekleneceği üzere <code class="language-plaintext highlighter-rouge">torch::TensorOptions</code> nesnesi geri döndürür :</p>

<div class="language-c++ highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">torch</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">randTensor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">::</span><span class="n">rand</span><span class="p">(</span><span class="cm">/*size:*/</span><span class="p">{</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">},</span> <span class="n">torch</span><span class="o">::</span><span class="n">TensorOptions</span><span class="p">().</span><span class="n">dtype</span><span class="p">(</span><span class="n">torch</span><span class="o">::</span><span class="n">kFloat32</span><span class="p">));</span>
<span class="cm">/* veya 
torch::Tensor randTensor = torch::rand({2, 3}, torch::dtype(torch::kFloat32));
torch::Tensor randTensor = torch::rand({2, 3}, torch::dtype(torch::kFloat32).device(torch::kCUDA, 0));
*/</span>
</code></pre></div></div>

<h3 id="112-torchrandint">1.1.2. <code class="language-plaintext highlighter-rouge">torch::randint()</code></h3>

<p>Bu fonksiyon verilen iki değer arasında düzgün dağılıma uygun şekilde tamsayılardan oluşan bir tensör geri döndürür. Hemen kullanımına bakalım:</p>

<div class="language-c++ highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">auto</span> <span class="n">intTensor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">::</span><span class="n">randint</span><span class="p">(</span><span class="cm">/*low:*/</span><span class="mi">1</span><span class="p">,</span> <span class="cm">/*high:*/</span><span class="mi">9</span><span class="p">,</span> <span class="cm">/*size:*/</span><span class="p">{</span><span class="mi">3</span><span class="p">});</span>
</code></pre></div></div>

<p>Yukarıdaki tanımlamayla 1 ile 9 arasında 3 elemanı olan bir vektör olacak bir tensör oluşturmuş oluyoruz. Bu tensörün çıktısına bakarsak:</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code> 6
 1
 1
<span class="o">[</span> CPUFloatType<span class="o">{</span>3<span class="o">}</span> <span class="o">]</span>
</code></pre></div></div>

<p>3B bir tensör (tipik olarak bir görüntü verisini taşıyan bir tensör olarak düşünebilirsiniz) oluşturalım:</p>

<div class="language-c++ highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">auto</span> <span class="n">intTensor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">::</span><span class="n">randint</span><span class="p">(</span><span class="cm">/*low:*/</span><span class="mi">1</span><span class="p">,</span> <span class="cm">/*high:*/</span><span class="mi">9</span><span class="p">,</span> <span class="cm">/*size:*/</span><span class="p">{</span><span class="mi">1920</span><span class="p">,</span> <span class="mi">1080</span><span class="p">,</span> <span class="mi">3</span><span class="p">});</span>
</code></pre></div></div>

<h3 id="113-torchonestorchzeros">1.1.3. torch::ones()/torch::zeros()</h3>

<p>Bu fonksiyonlar isimlerinden anlaşıldığı üzere birler veya sıfırlardan oluşan tensörler oluşturmanızı sağlarlar. Kullanımları yine diğer fonksiyonlarla benzerdir. Örneğin:</p>

<div class="language-c++ highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">auto</span> <span class="n">onesTensor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">::</span><span class="n">ones</span><span class="p">(</span><span class="cm">/*size:*/</span><span class="p">{</span><span class="mi">5</span><span class="p">,</span> <span class="mi">10</span><span class="p">});</span>
<span class="k">auto</span> <span class="n">zerosTensor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">::</span><span class="n">zeros</span><span class="p">(</span><span class="cm">/*size:*/</span><span class="p">{</span><span class="mi">1</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">10</span><span class="p">});</span>
</code></pre></div></div>

<h3 id="114-torchfrom_blob">1.1.4. <code class="language-plaintext highlighter-rouge">torch::from_blob()</code></h3>

<p>Çoğunlukla tensörü oluşturacak veriyi başka bir kaynaktan okuyupo bu tensöre aktarırız. Bunu yapabilmek için <code class="language-plaintext highlighter-rouge">void*</code> olarak veriyi alan ve tensör geri döndüren kullanışlı bir fonksiyon bulunmaktadır.:</p>

<div class="language-c++ highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kt">float</span> <span class="n">data</span><span class="p">[]</span> <span class="o">=</span> <span class="p">{</span><span class="mf">1.0</span><span class="p">,</span> <span class="mf">2.0</span><span class="p">,</span> <span class="mf">3.0</span><span class="p">,</span> <span class="mf">4.0</span><span class="p">,</span> <span class="mf">5.0</span><span class="p">,</span> <span class="mf">6.0</span><span class="p">,</span> <span class="mf">7.0</span> <span class="mf">8.0</span><span class="p">,</span> <span class="mf">9.0</span><span class="p">,</span> <span class="mf">10.0</span><span class="p">};</span>
<span class="k">auto</span> <span class="n">blobData</span> <span class="o">=</span> <span class="n">torch</span><span class="o">::</span><span class="n">from_blob</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="cm">/*size:*/</span><span class="p">{</span><span class="mi">2</span><span class="p">,</span> <span class="mi">5</span><span class="p">});</span>
<span class="cm">/*
  1   2   3   4   5
  6   7   8   9  10
[ CPUFloatType{2,5} ]
*/</span>
</code></pre></div></div>

<p><strong>Bu fonksiyonun argümanına gönderilen verinin sahipliğini almaz. Ancak tensör nesnesinin ömrü bittiğinde özgün nesneyi de bellekten siler.</strong>  Yine isterseniz tensör seçeneklerini kullanabilirsiniz.</p>

<div class="language-c++ highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">auto</span> <span class="n">blobDataD</span> <span class="o">=</span> <span class="n">torch</span><span class="o">::</span><span class="n">from_blob</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="p">{</span><span class="mi">1</span><span class="p">,</span> <span class="mi">10</span><span class="p">},</span> <span class="n">torch</span><span class="o">::</span><span class="n">requires_grad</span><span class="p">(</span><span class="n">False</span><span class="p">));</span>
</code></pre></div></div>

<h3 id="115-torchtensor-fonksiyonu">1.1.5. <code class="language-plaintext highlighter-rouge">torch::tensor</code> fonksiyonu</h3>

<p>Sınıfın kurucu işlevlerini doğrudan kullanan bu fonksiyonla da tensör oluşturmak söz konusudur.</p>

<pre><code class="language-C++">auto tensorInit = torch::tensor({1.0, 2.0, 4.0, 2.0, 3.0, 5.0});
</code></pre>

<p>Diğer fabrika fonksiyonlarına dokümantasyona bırakıp şimdi <code class="language-plaintext highlighter-rouge">torch::Tensor</code> sınıfının üye fonksiyonlarını inceleyelim.</p>

<h1 id="2-torchtensor-sınıf-üye-fonksiyonları">2. <code class="language-plaintext highlighter-rouge">torch::Tensor</code> Sınıf Üye Fonksiyonları</h1>

<p>Artık elimizde tensörümüz var ve onun hakkında bilgi almak/değişiklik yapmak istiyoruz. Burada <code class="language-plaintext highlighter-rouge">torch::Tensor</code> sınıfının bize sağladığı sınıf üye fonksiyonlarından en önemlilerine göz atalım:</p>

<div class="language-c++ highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">// 1 boyutlu bir tensör oluşturalım</span>
<span class="k">auto</span> <span class="n">tensorInit</span> <span class="o">=</span> <span class="n">torch</span><span class="o">::</span><span class="n">tensor</span><span class="p">({</span><span class="mf">1.0</span><span class="p">,</span> <span class="mf">2.0</span><span class="p">,</span> <span class="mf">4.0</span><span class="p">,</span> <span class="mf">2.0</span><span class="p">,</span> <span class="mf">3.0</span><span class="p">,</span> <span class="mf">5.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="mf">2.0</span><span class="p">,</span> <span class="mf">4.0</span><span class="p">,</span> <span class="mf">2.0</span><span class="p">,</span> <span class="mf">3.0</span><span class="p">,</span> <span class="mf">5.0</span><span class="p">});</span>
<span class="c1">// 2B tensöre dönüştürelim </span>
<span class="n">tensorInit</span> <span class="o">=</span> <span class="n">tensorInit</span><span class="p">.</span><span class="n">reshape</span><span class="p">({</span><span class="mi">2</span><span class="p">,</span><span class="mi">6</span><span class="p">});</span>

<span class="c1">// dim() sınıf üye fonksiyonu tensörün kaç boyutlu olduğunu geri döndürür. Örneğimizde 2 olarak:</span>
<span class="k">auto</span> <span class="n">tDims</span> <span class="o">=</span> <span class="n">tensorInit</span><span class="p">.</span><span class="n">dim</span><span class="p">();</span>

<span class="c1">// dtype() sınıf üye fonksiyonu tensörün veri tipini geri döndürür. Örneğimizde float olarak:</span>
<span class="k">auto</span> <span class="n">tDtype</span> <span class="o">=</span> <span class="n">tensorInit</span><span class="p">.</span><span class="n">dtype</span><span class="p">();</span>

<span class="c1">// sizes() sınıf üye fonksiyonu tensörün tuttuğu verinin şeklini geri döndürür. Örneğimizde  [2, 6] olarak:</span>
<span class="k">auto</span> <span class="n">f</span> <span class="o">=</span> <span class="n">tensorInit</span><span class="p">.</span><span class="n">sizes</span><span class="p">();</span>
</code></pre></div></div>

<h1 id="3-tensör-elemanlarına-erişim-i̇ndeksleme-ve-değiştirme">3. Tensör Elemanlarına Erişim, İndeksleme ve Değiştirme</h1>

<p>Tensör elemanlarına erişim için birden fazla yöntem bulunmaktadır. Öncelikle <code class="language-plaintext highlighter-rouge">torch::Tensor</code> sınıf üye fonksiyonlarından bir tanesi <code class="language-plaintext highlighter-rouge">torch::Tensor.data_ptr()</code> fonksiyonunu kullanarak tüm veriye erişebiliriz. Alternatif olarak <code class="language-plaintext highlighter-rouge">data()</code>fonksiyonunu kullanıp <em>Python</em>‘da olduğu gibi bir elemanına erişmek mümkündür.</p>

<div class="language-c++ highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">auto</span> <span class="n">tensorInit</span> <span class="o">=</span> <span class="n">torch</span><span class="o">::</span><span class="n">tensor</span><span class="p">({</span><span class="mf">1.0</span><span class="p">,</span> <span class="mf">2.0</span><span class="p">,</span> <span class="mf">4.0</span><span class="p">,</span> <span class="mf">2.0</span><span class="p">,</span> <span class="mf">3.0</span><span class="p">,</span> <span class="mf">5.0</span><span class="p">,</span> <span class="mf">11.0</span><span class="p">,</span> <span class="mf">12.0</span><span class="p">,</span> <span class="mf">14.0</span><span class="p">,</span> <span class="mf">12.0</span><span class="p">,</span> <span class="mf">13.0</span><span class="p">,</span> <span class="mf">15.0</span><span class="p">});</span>
<span class="n">tensorInit</span> <span class="o">=</span> <span class="n">tensorInit</span><span class="p">.</span><span class="n">reshape</span><span class="p">({</span><span class="mi">2</span><span class="p">,</span><span class="mi">6</span><span class="p">});</span>

<span class="c1">// void* türünden bir gösterici (pointer) geri döndürür</span>
<span class="k">auto</span> <span class="n">pDataVoid</span>  <span class="o">=</span> <span class="n">tensorInit</span><span class="p">.</span><span class="n">data_ptr</span><span class="p">();</span>
<span class="c1">// veri tipinin float olduğu varsayımıyla dönüştürüp göstericiyi kullanarak elemanlara ulaşabiliriz. </span>
<span class="k">auto</span> <span class="n">pDataFloat</span> <span class="o">=</span> <span class="k">static_cast</span><span class="o">&lt;</span><span class="kt">float</span><span class="o">*&gt;</span><span class="p">(</span><span class="n">pDataVoid</span><span class="p">);</span>
<span class="n">std</span><span class="o">::</span><span class="n">cout</span> <span class="o">&lt;&lt;</span> <span class="n">pDataFloat</span><span class="p">[</span><span class="mi">7</span><span class="p">]</span> <span class="o">&lt;&lt;</span> <span class="s">"</span><span class="se">\n</span><span class="s">"</span><span class="p">;</span> <span class="c1">// İki boyutta [1][1]  tek boyutta 7. eleman yani 12</span>

<span class="c1">// Alternatif olarak </span>
<span class="c1">// Doğrudan 1,0 indeksinde bulunan veriye data fonksiyonu ile de ulaşabiliriz.</span>
<span class="n">std</span><span class="o">::</span><span class="n">cout</span> <span class="o">&lt;&lt;</span> <span class="n">tensorInit</span><span class="p">.</span><span class="n">data</span><span class="p">()[</span><span class="mi">1</span><span class="p">][</span><span class="mi">1</span><span class="p">]</span> <span class="o">&lt;&lt;</span><span class="s">"</span><span class="se">\n</span><span class="s">"</span> <span class="p">;</span> <span class="c1">// örnekte 12</span>
</code></pre></div></div>

<p><em>LibTorch</em> ile veriye erişim için <code class="language-plaintext highlighter-rouge">torch::Tensor</code> kütüphanesinin sunduğu bir diğer alternatif ve tavsiye edilen yöntemse <code class="language-plaintext highlighter-rouge">accessor</code> kullanımıdır. Burada CPU ve GPU için ayrı <code class="language-plaintext highlighter-rouge">accessor</code> kullanmak gerekmektedir. Önce bir CPU tensörü için ardından da GPU tensörü için bu işlemi kullanalım:</p>

<div class="language-c++ highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">auto</span> <span class="n">tensorInit</span> <span class="o">=</span> <span class="n">torch</span><span class="o">::</span><span class="n">tensor</span><span class="p">({</span><span class="mf">1.0</span><span class="p">,</span> <span class="mf">2.0</span><span class="p">,</span> <span class="mf">4.0</span><span class="p">,</span> <span class="mf">2.0</span><span class="p">,</span> <span class="mf">3.0</span><span class="p">,</span> <span class="mf">5.0</span><span class="p">,</span> <span class="mf">11.0</span><span class="p">,</span> <span class="mf">12.0</span><span class="p">,</span> <span class="mf">14.0</span><span class="p">,</span> <span class="mf">12.0</span><span class="p">,</span> <span class="mf">13.0</span><span class="p">,</span> <span class="mf">15.0</span><span class="p">});</span>
<span class="n">tensorInit</span> <span class="o">=</span> <span class="n">tensorInit</span><span class="p">.</span><span class="n">reshape</span><span class="p">({</span><span class="mi">2</span><span class="p">,</span><span class="mi">6</span><span class="p">});</span>

<span class="k">auto</span> <span class="n">tensorInitAccessor</span> <span class="o">=</span> <span class="n">tensorInit</span><span class="p">.</span><span class="n">accessor</span><span class="o">&lt;</span><span class="kt">float</span><span class="p">,</span> <span class="mi">2</span><span class="o">&gt;</span><span class="p">();</span>
<span class="k">for</span> <span class="p">(</span><span class="kt">int</span> <span class="n">i</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="n">tensorInitAccessor</span><span class="p">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">);</span> <span class="n">i</span><span class="o">++</span><span class="p">)</span>
    <span class="k">for</span> <span class="p">(</span><span class="kt">int</span> <span class="n">j</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="n">j</span> <span class="o">&lt;</span> <span class="n">tensorInitAccessor</span><span class="p">.</span><span class="n">size</span><span class="p">(</span><span class="mi">1</span><span class="p">);</span> <span class="n">j</span><span class="o">++</span><span class="p">)</span> <span class="p">{</span>
        <span class="n">std</span><span class="o">::</span><span class="n">cout</span> <span class="o">&lt;&lt;</span> <span class="s">"Data in position "</span> <span class="o">&lt;&lt;</span> <span class="n">i</span> <span class="o">&lt;&lt;</span> <span class="s">"-"</span> <span class="o">&lt;&lt;</span> <span class="n">j</span> <span class="o">&lt;&lt;</span> <span class="s">": "</span> <span class="o">&lt;&lt;</span> <span class="n">tensorInitAccessor</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="n">j</span><span class="p">]</span> <span class="o">&lt;&lt;</span> <span class="s">"</span><span class="se">\n</span><span class="s">"</span><span class="p">;</span>
    <span class="p">}</span>
</code></pre></div></div>

<p>Bu kullanımda dikkat edilecek husus <code class="language-plaintext highlighter-rouge">accessor</code> nesnenin şablon parametrelerine veri tipi olan <code class="language-plaintext highlighter-rouge">float</code> ve boyutu gösteren <code class="language-plaintext highlighter-rouge">2</code> göndermemiz gerektiğidir. Yani farklı veri tipi ve boyutlar için bir özelleşme gerekecektir. Yani işleri çokta kısalttığını söyleyemem. Dokümantasyonun iddiası daha hızlı erişim sağladığı yönünde ama gösterici kullanımının yavaş olmasını pek mümkün görmediğim için büyük bir tensörde tüm elemanlara ulaşmayı test etmek istedim:</p>

<div class="language-c++ highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="cp">#include</span> <span class="cpf">&lt;iostream&gt;</span><span class="cp">
#include</span> <span class="cpf">&lt;torch/torch.h&gt;</span><span class="cp">
#include</span> <span class="cpf">&lt;chrono&gt;</span><span class="cp">
</span>
<span class="kt">int</span> <span class="nf">main</span><span class="p">()</span> <span class="p">{</span>
    <span class="k">using</span> <span class="k">namespace</span> <span class="n">std</span><span class="o">::</span><span class="n">chrono</span><span class="p">;</span>
    
    <span class="k">const</span> <span class="kt">int</span> <span class="n">HEIGHT</span> <span class="o">=</span> <span class="mi">1920</span><span class="p">,</span> <span class="n">WIDTH</span> <span class="o">=</span> <span class="mi">1080</span><span class="p">,</span> <span class="n">CH</span> <span class="o">=</span> <span class="mi">300</span><span class="p">;</span>
    <span class="kt">long</span> <span class="kt">double</span> <span class="n">sum</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span>
    
    <span class="k">auto</span> <span class="n">randBigTensor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">::</span><span class="n">rand</span><span class="p">({</span><span class="n">HEIGHT</span><span class="p">,</span> <span class="n">WIDTH</span><span class="p">,</span> <span class="n">CH</span><span class="p">});</span>
    
    <span class="k">auto</span> <span class="n">start</span> <span class="o">=</span> <span class="n">high_resolution_clock</span><span class="o">::</span><span class="n">now</span><span class="p">();</span>
    <span class="k">auto</span> <span class="n">tensorInitAccessor</span> <span class="o">=</span> <span class="n">randBigTensor</span><span class="p">.</span><span class="n">accessor</span><span class="o">&lt;</span><span class="kt">float</span><span class="p">,</span> <span class="mi">3</span><span class="o">&gt;</span><span class="p">();</span>
    <span class="k">for</span> <span class="p">(</span><span class="kt">int</span> <span class="n">i</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="n">tensorInitAccessor</span><span class="p">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">);</span> <span class="n">i</span><span class="o">++</span><span class="p">)</span>
        <span class="k">for</span> <span class="p">(</span><span class="kt">int</span> <span class="n">j</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="n">j</span> <span class="o">&lt;</span> <span class="n">tensorInitAccessor</span><span class="p">.</span><span class="n">size</span><span class="p">(</span><span class="mi">1</span><span class="p">);</span> <span class="n">j</span><span class="o">++</span><span class="p">)</span>
            <span class="k">for</span> <span class="p">(</span><span class="kt">int</span> <span class="n">k</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="n">k</span> <span class="o">&lt;</span> <span class="n">tensorInitAccessor</span><span class="p">.</span><span class="n">size</span><span class="p">(</span><span class="mi">2</span><span class="p">);</span> <span class="n">k</span><span class="o">++</span><span class="p">)</span> <span class="p">{</span>
                <span class="n">sum</span> <span class="o">+=</span> <span class="p">(</span><span class="n">tensorInitAccessor</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="n">j</span><span class="p">][</span><span class="n">k</span><span class="p">])</span> <span class="o">/</span> <span class="mi">1000</span><span class="p">;</span>
            <span class="p">}</span>
    <span class="k">auto</span> <span class="n">end</span> <span class="o">=</span> <span class="n">high_resolution_clock</span><span class="o">::</span><span class="n">now</span><span class="p">();</span>
    <span class="n">duration</span><span class="o">&lt;</span><span class="kt">double</span><span class="o">&gt;</span> <span class="n">time_span</span> <span class="o">=</span> <span class="n">duration_cast</span><span class="o">&lt;</span><span class="n">duration</span><span class="o">&lt;</span><span class="kt">double</span><span class="o">&gt;&gt;</span><span class="p">(</span><span class="n">end</span> <span class="o">-</span> <span class="n">start</span><span class="p">);</span>
    <span class="n">std</span><span class="o">::</span><span class="n">cout</span> <span class="o">&lt;&lt;</span> <span class="s">"It took me "</span> <span class="o">&lt;&lt;</span> <span class="n">time_span</span><span class="p">.</span><span class="n">count</span><span class="p">()</span> <span class="o">&lt;&lt;</span> <span class="s">" seconds (Using accesscor). Sum = "</span> <span class="o">&lt;&lt;</span> <span class="n">sum</span> <span class="o">&lt;&lt;</span> <span class="s">"</span><span class="se">\n</span><span class="s">"</span><span class="p">;</span>

    <span class="n">sum</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span>
    <span class="n">start</span> <span class="o">=</span> <span class="n">high_resolution_clock</span><span class="o">::</span><span class="n">now</span><span class="p">();</span>
    <span class="k">auto</span> <span class="n">pDataVoid</span> <span class="o">=</span> <span class="n">randBigTensor</span><span class="p">.</span><span class="n">data_ptr</span><span class="p">();</span>
    <span class="k">auto</span> <span class="n">pDataFloat</span> <span class="o">=</span> <span class="k">static_cast</span><span class="o">&lt;</span><span class="kt">float</span> <span class="o">*&gt;</span><span class="p">(</span><span class="n">pDataVoid</span><span class="p">);</span>
    <span class="k">for</span> <span class="p">(</span><span class="kt">int</span> <span class="n">i</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="p">(</span><span class="n">HEIGHT</span> <span class="o">*</span> <span class="n">WIDTH</span> <span class="o">*</span> <span class="n">CH</span><span class="p">);</span> <span class="n">i</span><span class="o">++</span><span class="p">)</span>
        <span class="n">sum</span> <span class="o">+=</span> <span class="p">(</span><span class="n">pDataFloat</span><span class="p">[</span><span class="n">i</span><span class="p">])</span> <span class="o">/</span> <span class="mi">1000</span><span class="p">;</span>
    <span class="n">end</span> <span class="o">=</span> <span class="n">high_resolution_clock</span><span class="o">::</span><span class="n">now</span><span class="p">();</span>
    <span class="n">time_span</span> <span class="o">=</span> <span class="n">duration_cast</span><span class="o">&lt;</span><span class="n">duration</span><span class="o">&lt;</span><span class="kt">double</span><span class="o">&gt;&gt;</span><span class="p">(</span><span class="n">end</span> <span class="o">-</span> <span class="n">start</span><span class="p">);</span>
    <span class="n">std</span><span class="o">::</span><span class="n">cout</span> <span class="o">&lt;&lt;</span> <span class="s">"It took me "</span> <span class="o">&lt;&lt;</span> <span class="n">time_span</span><span class="p">.</span><span class="n">count</span><span class="p">()</span> <span class="o">&lt;&lt;</span> <span class="s">" seconds (Using data_ptr). Sum = "</span> <span class="o">&lt;&lt;</span> <span class="n">sum</span> <span class="o">&lt;&lt;</span> <span class="s">"</span><span class="se">\n</span><span class="s">"</span><span class="p">;</span>
    
    <span class="k">return</span> <span class="mi">0</span><span class="p">;</span>
<span class="p">}</span>
</code></pre></div></div>

<p>Sonuçlar aslında beklediğim gibi oldu. En hızlısı veri göstericiyi alıp veriye erişmek oldu. Ama bu testi farklı boyutlarda hatta ideali uygulamanızda kullanacağınız tensör boyutlarıyla test etmek daha mantıklı olabileceğini düşünüyorum.</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code>It took me 18.573 seconds <span class="o">(</span>Using accesscor<span class="o">)</span><span class="nb">.</span> Sum <span class="o">=</span> 311033
It took me 4.24126 seconds <span class="o">(</span>Using data_ptr<span class="o">)</span><span class="nb">.</span> Sum <span class="o">=</span> 311033
</code></pre></div></div>

<p>Bazen bu verinin belirli elemanlarına erişmek isteyebiliriz. Bu durumda <em>Python</em>‘dan alışık olduğumuz Indexing API kullanımı daha kolay olacaktır. Bu API’de hem okuma hem de yazma işlemi yapmak mümkündür:</p>

<div class="language-c++ highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">auto</span> <span class="n">randTensor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">::</span><span class="n">rand</span><span class="p">({</span><span class="mi">100</span><span class="p">,</span> <span class="mi">100</span><span class="p">,</span> <span class="mi">3</span><span class="p">});</span>

<span class="c1">//1,0,5 konumundaki eleman</span>
<span class="n">std</span><span class="o">::</span><span class="n">cout</span> <span class="o">&lt;&lt;</span> <span class="n">randTensor</span><span class="p">.</span><span class="n">index</span><span class="p">({</span><span class="mi">1</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">5</span><span class="p">});</span> 

<span class="c1">// Slice fonksiyonuyla 0.boyuttaki verileri 1.indeksten başlayıp 10'a kadar 2'şer artan şekilde alır ve diğer iki eksende 0. indekse denk gelen elemanları gösterir. Burada `torch::indexing` isim alanının eklendiğine dikkat edin.  </span>
<span class="k">using</span> <span class="k">namespace</span> <span class="n">torch</span><span class="o">::</span><span class="n">indexing</span><span class="p">;</span>
<span class="n">std</span><span class="o">::</span><span class="n">cout</span> <span class="o">&lt;&lt;</span> <span class="n">randTensor</span><span class="p">.</span><span class="n">index</span><span class="p">({</span><span class="n">Slice</span><span class="p">(</span><span class="cm">/*start_idx:*/</span><span class="mi">1</span><span class="p">,</span> <span class="cm">/*stop_idx:*/</span><span class="mi">10</span><span class="p">,</span> <span class="cm">/*step:*/</span><span class="mi">2</span><span class="p">),</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">})});</span> 

<span class="c1">//1,0,5 konumundaki elemana değer atama</span>
<span class="n">randTensor</span><span class="p">.</span><span class="n">index</span><span class="p">({</span><span class="mi">1</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">5</span><span class="p">})</span> <span class="o">=</span> <span class="mf">0.05</span>
</code></pre></div></div>

<p>Indexing API’nin <em>Python</em> ve <em>C++</em> için kullanımının kıyaslaması için <a href="https://pytorch.org/cppdocs/notes/tensor_indexing.html">bağlantıya</a> tıklayın.</p>

<h1 id="4-dönüşüm-i̇şlemleri">4. Dönüşüm İşlemleri</h1>

<p>Bu yazıyı bitirmeden önce son olarak tensörlerin dönüşüm işlemlerine bakalım.  Burada ilk oluşturma esnasında belirlediğimiz tensör seçeneklerini dönüştürmek mümkündür.</p>

<div class="language-c++ highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">auto</span> <span class="n">sourceTensor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">::</span><span class="n">randn</span><span class="p">({</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">},</span> <span class="n">torch</span><span class="o">::</span><span class="n">kFloat16</span><span class="p">);</span>

<span class="c1">// Veri tipini dönüştürme</span>
<span class="k">auto</span> <span class="n">floatTensor32</span> <span class="o">=</span> <span class="n">sourceTensor</span><span class="p">.</span><span class="n">to</span><span class="p">(</span><span class="n">torch</span><span class="o">::</span><span class="n">kFloat32</span><span class="p">);</span>

<span class="c1">// Aygıt tipine göre dönüştürme</span>
<span class="k">auto</span> <span class="n">gpuTensor</span> <span class="o">=</span> <span class="n">floatTensor32</span><span class="p">.</span><span class="n">to</span><span class="p">(</span><span class="n">torch</span><span class="o">::</span><span class="n">kCUDA</span><span class="p">);</span>
</code></pre></div></div>

<p>Evet yazının sonuna geldik. Yazı dizisinin bir sonraki yazısında artık modellere doğru geçiş yapacağımız yazı hazır olduğunda bu yazının altına bağlantıyı ekleyeceğim.</p>

<p><em>Dizinin diğer yazıları:</em></p>

<ol>
  <li>
    <p><a href="https://blgnksy.github.io/tr/2020/12/03/libtorch-config.html">C++ Derin Öğrenme-1 Pytorch C++ API LibTorch Giriş</a></p>
  </li>
  <li>
    <p><a href="https://blgnksy.github.io/tr/2020/12/13/libtorch-inference.html">C++ Derin Öğrenme-3 Pytorch C++ API LibTorch Modelleri Çalıştırma</a></p>
  </li>
</ol>

</section>
   
   <!-- Tag list -->
  
  


<footer>
  <div class="tag-list">
    
      <div class="meta">Tags</div>
    

    
    <a class="button" href="/tags#Deep Learning">
      <p><i class="fa fa-tag fa-fw"></i> Deep Learning</p>
    </a>
    
    <a class="button" href="/tags#Deep Learning C++">
      <p><i class="fa fa-tag fa-fw"></i> Deep Learning C++</p>
    </a>
    
    <a class="button" href="/tags#Derin Öğrenme">
      <p><i class="fa fa-tag fa-fw"></i> Derin Öğrenme</p>
    </a>
    
    <a class="button" href="/tr/tags#LibTorch">
      <p><i class="fa fa-tag fa-fw"></i> LibTorch</p>
    </a>
    
    <a class="button" href="/tags#Machine Learning">
      <p><i class="fa fa-tag fa-fw"></i> Machine Learning</p>
    </a>
    
    <a class="button" href="/tags#Machine Learning C++">
      <p><i class="fa fa-tag fa-fw"></i> Machine Learning C++</p>
    </a>
    
    <a class="button" href="/tags#Makine Öğrenmesi">
      <p><i class="fa fa-tag fa-fw"></i> Makine Öğrenmesi</p>
    </a>
    
    <a class="button" href="/tr/tags#PyTorch">
      <p><i class="fa fa-tag fa-fw"></i> PyTorch</p>
    </a>
    
    <a class="button" href="/tags#PyTorch C++ API">
      <p><i class="fa fa-tag fa-fw"></i> PyTorch C++ API</p>
    </a>
    
    <a class="button" href="/tr/tags#Tensors">
      <p><i class="fa fa-tag fa-fw"></i> Tensors</p>
    </a>
    
    <a class="button" href="/tags#Tensör İşlemleri">
      <p><i class="fa fa-tag fa-fw"></i> Tensör İşlemleri</p>
    </a>
    
  </div>
</footer>

    
  <!-- Structured Data for Blog Post -->
  <script type="application/ld+json">
  {
    "@context": "https://schema.org",
    "@type": "BlogPosting",
    "headline": "C++ Derin Öğrenme-2 Pytorch C++ API LibTorch Tensör İşlemleri",
    "author": {
      "@type": "Person",
      "name": ""
    },
    "datePublished": "2020-12-06T00:00:00+00:00",
    "dateModified": "2020-12-06T00:00:00+00:00",
    "mainEntityOfPage": {
      "@type": "WebPage",
      "@id": "https://blgnksy.github.io/2020/12/06/libtorch-tensors.html"
    },
    "publisher": {
      "@type": "Organization",
      "name": "NDeep",
      "logo": {
        "@type": "ImageObject",
        "url": "https://blgnksy.github.io/assets/favicon.ico"
      }
    },
    "image": "https://blgnksy.github.io",
    "articleSection": "",
    "keywords": "Deep Learning, Derin Öğrenme, PyTorch, LibTorch, PyTorch C++ API, Machine Learning C++, Deep Learning C++, Machine Learning, Makine Öğrenmesi, Tensors, Tensör İşlemleri",
    "inLanguage": "tr"
  }
  </script>
    
</article>

<!-- Disqus -->

<div id="disqus_thread"></div>
    <script type="text/javascript">
        /* * * CONFIGURATION VARIABLES: EDIT BEFORE PASTING INTO YOUR WEBPAGE * * */
        var disqus_shortname = 'https-blgnksy-github-io'; // required: replace example with your forum shortname
        /*var disqus_developer = 1; // Comment out when the site is live*/
        var disqus_identifier = "/2020/12/06/libtorch-tensors.html";

        /* * * DON'T EDIT BELOW THIS LINE * * */
        (function() {
            var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
            dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
            (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
        })();
    </script>
    <noscript>Please enable JavaScript to view the <a href="http://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
    <a href="http://disqus.com" class="dsq-brlink">comments powered by <span class="logo-disqus">Disqus</span></a>




<!-- Post navigation -->

  <div id="post-nav">
  
  <div id="previous-post" class="post-nav-post">
      <p>Previous post</p>
      <a href="/tr/2020/12/03/libtorch-config.html">
        C++ Derin Öğrenme-1 Pytorch C++ API LibTorch Giriş
      </a>
  </div>
  
  
  <div id="next-post" class="post-nav-post">
      <p>Next post</p>
      <a href="/tr/2020/12/13/libtorch-inference.html">
        C++ Derin Öğrenme-3 Pytorch C++ API LibTorch Modelleri Çalıştırma
      </a>
  </div>
  
</div>


    </div>
    
<footer class="site-footer">
    <p class="text">Powered by <a href="https://jekyllrb.com/">Jekyll</a> with <a href="https://github.com/sylhare/Type-on-Strap">Type on Strap</a>
</p>
            <div class="footer-icons">
                <ul>
                <!-- Social icons from Font Awesome, if enabled -->
                


<li>
	<a href="mailto:bilgin.aksoy@metu.edu.tr" title="Email">
		<span class="fa-stack fa-lg">
            <i class="fa fa-circle fa-stack-2x"></i>
            <i class="fa fa-envelope fa-stack-1x fa-inverse"></i>
        </span>
	</a>
</li>





<li>
	<a href="https://bitbucket.org/blgnksy" title="Follow on Bitbucket">
		<span class="fa-stack fa-lg">
            <i class="fa fa-circle fa-stack-2x"></i>
            <i class="fa fa-bitbucket fa-stack-1x fa-inverse"></i>
        </span>
	</a>
</li>









<li>
	<a href="https://github.com/blgnksy" title="Follow on GitHub">
		<span class="fa-stack fa-lg">
            <i class="fa fa-circle fa-stack-2x"></i>
            <i class="fa fa-github fa-stack-1x fa-inverse"></i>
        </span>
	</a>
</li>









<li>
	<a href="https://www.linkedin.com/in/bilgin-aksoy-a61a90110" title="Follow on LinkedIn">
		<span class="fa-stack fa-lg">
            <i class="fa fa-circle fa-stack-2x"></i>
            <i class="fa fa-linkedin fa-stack-1x fa-inverse"></i>
        </span>
	</a>
</li>

















<li>
	<a href="https://twitter.com/blgnksy" title="Follow on Twitter" class="type">
        <span class="fa-stack fa-lg">
            <i class="fa fa-circle fa-stack-2x"></i>
            <i class="fa fa-twitter fa-stack-1x fa-inverse"></i>
        </span>
	</a>
</li>








                </ul>
            </div>
</footer>




  </body>
</html>
<script type="text/javascript">
      /* * * CONFIGURATION VARIABLES: EDIT BEFORE PASTING INTO YOUR WEBPAGE * * */
      var disqus_shortname = 'https-blgnksy-github-io'; // required: replace example with your forum shortname
      //var disqus_developer = 1; // Comment out when the site is live

      /* * * DON'T EDIT BELOW THIS LINE * * */
      (function () {
        var s = document.createElement('script'); s.async = true;
        s.type = 'text/javascript';
        s.src = 'http://' + disqus_shortname + '.disqus.com/count.js';
        (document.getElementsByTagName('HEAD')[0] || document.getElementsByTagName('BODY')[0]).appendChild(s);
      }());
    </script>
