<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">

    <!-- JQuery (used for bootstrap and jekyll search) -->
    <script src="/assets/js/jquery-3.2.1.min.js" ></script>

    <!-- Main JS (navbar.js and katex_init.js)-->
    <script defer=true src="/assets/js/main.min.js"></script>

    <!-- CSS -->
    <link rel="stylesheet" href="/tr/assets/css/main.css">

    <!--Favicon-->
    <link rel="shortcut icon" href="/tr/assets/favicon.ico" type="image/x-icon">

    <!-- Canonical -->
    <link rel="canonical" href="https://blgnksy.github.io/tr/2020/12/13/libtorch-inference.html">

    <!-- RSS -->
    <link rel="alternate" type="application/atom+xml" title="NDeep" href="https://blgnksy.github.io/tr///feed.xml"/>

    <!-- Font Awesome -->
    <!-- <link href="/tr//maxcdn.bootstrapcdn.com/font-awesome/4.7.0/css/font-awesome.min.css" rel="stylesheet"> -->
    <link rel="stylesheet" type="text/css" href="/tr/assets/css/font-awesome.min.css">

    <!-- Google Fonts -->
    
    <link href="/tr//fonts.googleapis.com/css?family=Source+Sans+Pro:400,700,700italic,400italic" rel="stylesheet" type="text/css">
    

    <!-- KaTeX 0.8.3 -->
    
    <!--<link rel="stylesheet" href="/tr//cdnjs.cloudflare.com/ajax/libs/KaTeX/0.8.3/katex.min.css">
    <script src="//cdnjs.cloudflare.com/ajax/libs/KaTeX/0.8.3/katex.min.js"></script> -->
    <link rel="stylesheet" type="text/css" href="/tr/assets/css/katex.min.css">
    <script src="/assets/js/katex.min.js">
    </script>
    


    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-NWPYEC2Z49"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'G-NWPYEC2Z49');
    </script>


    <!-- Google Analytics -->
    
    <script>
        (function(i, s, o, g, r, a, m) {
            i['GoogleAnalyticsObject'] = r;
            i[r] = i[r] || function() {
                (i[r].q = i[r].q || []).push(arguments)
            }, i[r].l = 1 * new Date();
            a = s.createElement(o),
                m = s.getElementsByTagName(o)[0];
            a.async = 1;
            a.src = g;
            m.parentNode.insertBefore(a, m)
        })(window, document, 'script', '//www.google-analytics.com/analytics.js', 'ga');

        ga('create', 'G-NWPYEC2Z49', 'auto');
        ga('send', 'pageview');

    </script>
    

    <!-- seo tags -->
    <!-- Begin Jekyll SEO tag v2.8.0 -->
<title>C++ Derin Öğrenme-3 Pytorch C++ API LibTorch Modelleri Çalıştırma | Blog About Deep/Machine Learning, CUDA, Computer Vision</title>
<meta name="generator" content="Jekyll v3.10.0" />
<meta property="og:title" content="C++ Derin Öğrenme-3 Pytorch C++ API LibTorch Modelleri Çalıştırma" />
<meta property="og:locale" content="tr" />
<meta name="description" content="Yazı dizisinin bu yazısında LibTorch‘u kullanarak modelleri nasıl çalıştıracağımızı, çıkarım (inference) için nasıl kullanacağımızı göreceğiz. Yazı dizisinin ilk yazısında kullanım senaryolarını açıklarken Python‘da eğitilen modeli C++‘da çıkarım için kullanıp bazı darboğazları atlatabileceğinizi aktarmıştım. Şimdi Python‘da bir modeli eğitip (bununla zaman kaybetmemek için öneğitimli bir modeli kullanacağım), kaydedip C++‘da yükleyip çıkarım yapacağız." />
<meta property="og:description" content="Yazı dizisinin bu yazısında LibTorch‘u kullanarak modelleri nasıl çalıştıracağımızı, çıkarım (inference) için nasıl kullanacağımızı göreceğiz. Yazı dizisinin ilk yazısında kullanım senaryolarını açıklarken Python‘da eğitilen modeli C++‘da çıkarım için kullanıp bazı darboğazları atlatabileceğinizi aktarmıştım. Şimdi Python‘da bir modeli eğitip (bununla zaman kaybetmemek için öneğitimli bir modeli kullanacağım), kaydedip C++‘da yükleyip çıkarım yapacağız." />
<link rel="canonical" href="https://blgnksy.github.io/tr/2020/12/13/libtorch-inference.html" />
<meta property="og:url" content="https://blgnksy.github.io/2020/12/13/libtorch-inference.html" />
<meta property="og:site_name" content="Blog About Deep/Machine Learning, CUDA, Computer Vision" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2020-12-13T00:00:00+00:00" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:title" content="C++ Derin Öğrenme-3 Pytorch C++ API LibTorch Modelleri Çalıştırma" />
<script type="application/ld+json">
{"@context":"https://schema.org","@type":"BlogPosting","dateModified":"2020-12-13T00:00:00+00:00","datePublished":"2020-12-13T00:00:00+00:00","description":"Yazı dizisinin bu yazısında LibTorch‘u kullanarak modelleri nasıl çalıştıracağımızı, çıkarım (inference) için nasıl kullanacağımızı göreceğiz. Yazı dizisinin ilk yazısında kullanım senaryolarını açıklarken Python‘da eğitilen modeli C++‘da çıkarım için kullanıp bazı darboğazları atlatabileceğinizi aktarmıştım. Şimdi Python‘da bir modeli eğitip (bununla zaman kaybetmemek için öneğitimli bir modeli kullanacağım), kaydedip C++‘da yükleyip çıkarım yapacağız.","headline":"C++ Derin Öğrenme-3 Pytorch C++ API LibTorch Modelleri Çalıştırma","mainEntityOfPage":{"@type":"WebPage","@id":"https://blgnksy.github.io/2020/12/13/libtorch-inference.html"},"url":"https://blgnksy.github.io/2020/12/13/libtorch-inference.html"}</script>
<!-- End Jekyll SEO tag -->

    <!-- Manual seo tags -->
    <!--
    <title>C++ Derin Öğrenme-3 Pytorch C++ API LibTorch Modelleri Çalıştırma | NDeep</title>
    <meta name="description" content="Yazı dizisinin bu yazısında LibTorch‘u kullanarak modelleri nasıl çalıştıracağımızı, çıkarım (inference) için nasıl kullanacağımızı göreceğiz. Yazı dizisinin...">
    -->

    <!-- Structured Data -->
    <script type="application/ld+json">
    {
      "@context": "https://schema.org",
      "@type": "WebSite",
      "name": "NDeep",
      "url": "https://blgnksy.github.io",
      "description": "",
      "inLanguage": "tr",
      "potentialAction": {
        "@type": "SearchAction",
        "target": "https://blgnksy.github.io/search/?q={search_term_string}",
        "query-input": "required name=search_term_string"
      }
    }
    </script>
</head>

  <body>
    <header class="site-header">
    
    <!-- Logo and title -->
	<div class="branding">
		<a href="/tr/">
			<img class="avatar" src="/assets/img/triangle.svg" alt=""/>
		</a>

		<h1 class="site-title">
			<a href="/tr/">NDeep</a>
		</h1>
	</div>
    
    <!-- Toggle menu -->
    <nav class="clear">
    <a id="pull" class="toggle" href="#">
    <i class="fa fa-bars fa-lg"></i>
    </a>
    
    <!-- Menu -->
    <ul>
        
        
        
        
        <li class="separator">
            |
        </li>
        <li>
            <a class="clear" href="/tr/about/">
                Hakkımda
            </a>
        </li>
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
         
        
        
        <li class="separator">
            |
        </li>
        <li>
            <a class="clear" href="https://blgnksy.github.io/tr/search">
                <i class="fa fa-search" aria-hidden="true"></i>
            </a>
        </li>
        
        
        <li class="separator">
            |
        </li>
        <li>
            <a class="clear" href="https://blgnksy.github.io/tr/tags">
                <i class="fa fa-tags" aria-hidden="true"></i>
            </a>
        </li>
        
        
        
        
    </ul>
        
	</nav>
</header>

    <div class="content">
      <article >
  <header id="main" style="background-image: url('/')">
    <h1 id="C%2B%2B+Derin+%C3%96%C4%9Frenme-3+Pytorch+C%2B%2B+API+LibTorch+Modelleri+%C3%87al%C4%B1%C5%9Ft%C4%B1rma" class="title">C++ Derin Öğrenme-3 Pytorch C++ API LibTorch Modelleri Çalıştırma</h1>
    <p class="meta">
    December 13, 2020
    
    </p>
  </header>
  <section class="post-content"><p>Yazı dizisinin bu yazısında <em>LibTorch</em>‘u kullanarak modelleri nasıl çalıştıracağımızı, çıkarım (inference) için nasıl kullanacağımızı göreceğiz. Yazı dizisinin ilk yazısında kullanım senaryolarını açıklarken <em>Python</em>‘da eğitilen modeli <em>C++</em>‘da çıkarım için kullanıp bazı darboğazları atlatabileceğinizi aktarmıştım. Şimdi <em>Python</em>‘da bir modeli eğitip (bununla zaman kaybetmemek için öneğitimli bir modeli kullanacağım), kaydedip <em>C++</em>‘da yükleyip çıkarım yapacağız.</p>

<p>İlk önce <em>Python</em>‘da bir model eğittimizi ve modelin <code class="language-plaintext highlighter-rouge">resnet152</code> nesnesinde tutulduğunu varsayalım. Dediğim gibi ben doğrudan öneğitimli bir model kullanacağım:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">torchvision.models</span> <span class="k">as</span> <span class="n">models</span>
<span class="kn">import</span> <span class="nn">torch</span>

<span class="n">resnet152</span> <span class="o">=</span> <span class="n">models</span><span class="p">.</span><span class="n">resnet152</span><span class="p">(</span><span class="n">pretrained</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>

<span class="n">script</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">jit</span><span class="p">.</span><span class="n">script</span><span class="p">(</span><span class="n">resnet152</span><span class="p">)</span>
<span class="n">traced</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">jit</span><span class="p">.</span><span class="n">trace</span><span class="p">(</span><span class="n">resnet152</span><span class="p">,</span> <span class="n">torch</span><span class="p">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">224</span><span class="p">,</span> <span class="mi">224</span><span class="p">))</span> <span class="c1">#Traced model için örnek girdi sağlanmalıdır.
</span>
<span class="n">script</span><span class="p">.</span><span class="n">save</span><span class="p">(</span><span class="s">"./model_zoo/resnet152_sc.pt"</span><span class="p">)</span>
<span class="n">traced</span><span class="p">.</span><span class="n">save</span><span class="p">(</span><span class="s">"./model_zoo/resnet152_tr.pt"</span><span class="p">)</span>
</code></pre></div></div>

<p>Burada modeli <code class="language-plaintext highlighter-rouge">torch</code>‘un <code class="language-plaintext highlighter-rouge">jit</code> modülünü kullanarak hem <code class="language-plaintext highlighter-rouge">script</code> modunda hem de <code class="language-plaintext highlighter-rouge">trace</code> modunda kaydedelim. <em>Python API</em>‘da <code class="language-plaintext highlighter-rouge">jit</code> modülünün kullanımı hakkında bilgi sahibi değilseniz kısa bir ara verip <a href="https://pytorch.org/tutorials/beginner/Intro_to_TorchScript_tutorial.html">dokümantasyonu</a> okumanızı tavsiye ederim. Her ikisini de kaydetme nedenim ileride karşılaştırma için kullanacak olmamdır. Şimdi kaydedilen modelleri kullanarak <em>C++</em>‘da hızlıca çıkarım yapalım:</p>

<div class="language-c++ highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="cp">#include</span> <span class="cpf">&lt;torch/script.h&gt;</span><span class="cp">
#include</span> <span class="cpf">&lt;iostream&gt;</span><span class="cp">
</span>
<span class="kt">int</span> <span class="nf">main</span><span class="p">(</span><span class="kt">int</span> <span class="n">argc</span><span class="p">,</span> <span class="k">const</span> <span class="kt">char</span><span class="o">*</span> <span class="n">argv</span><span class="p">[])</span> <span class="p">{</span>
    <span class="k">if</span> <span class="p">(</span><span class="n">argc</span> <span class="o">!=</span> <span class="mi">2</span><span class="p">)</span> <span class="p">{</span>
        <span class="n">std</span><span class="o">::</span><span class="n">cerr</span> <span class="o">&lt;&lt;</span> <span class="s">"Usage: infer &lt;path-to-exported-script-module&gt;</span><span class="se">\n</span><span class="s">"</span><span class="p">;</span>
        <span class="k">return</span> <span class="o">-</span><span class="mi">1</span><span class="p">;</span>
    <span class="p">}</span>

    <span class="n">at</span><span class="o">::</span><span class="n">globalContext</span><span class="p">().</span><span class="n">setBenchmarkCuDNN</span><span class="p">(</span><span class="mi">1</span><span class="p">);</span>
    <span class="n">torch</span><span class="o">::</span><span class="n">jit</span><span class="o">::</span><span class="n">script</span><span class="o">::</span><span class="n">Module</span> <span class="n">module</span><span class="p">;</span>
    <span class="k">try</span> <span class="p">{</span>
        <span class="c1">// Deserialize the ScriptModule from a file.</span>
        <span class="n">module</span> <span class="o">=</span> <span class="n">torch</span><span class="o">::</span><span class="n">jit</span><span class="o">::</span><span class="n">load</span><span class="p">(</span><span class="n">argv</span><span class="p">[</span><span class="mi">1</span><span class="p">]);</span>
        <span class="n">std</span><span class="o">::</span><span class="n">cout</span> <span class="o">&lt;&lt;</span> <span class="s">"Module loaded successfully.</span><span class="se">\n</span><span class="s">"</span><span class="p">;</span>
        <span class="n">module</span><span class="p">.</span><span class="n">eval</span><span class="p">();</span>
    <span class="p">}</span>
    <span class="k">catch</span> <span class="p">(</span><span class="k">const</span> <span class="n">c10</span><span class="o">::</span><span class="n">Error</span><span class="o">&amp;</span> <span class="n">e</span><span class="p">)</span> <span class="p">{</span>
        <span class="n">std</span><span class="o">::</span><span class="n">cerr</span> <span class="o">&lt;&lt;</span> <span class="s">"Error loading the model.</span><span class="se">\n</span><span class="s">"</span><span class="p">;</span>
        <span class="k">return</span> <span class="o">-</span><span class="mi">1</span><span class="p">;</span>
    <span class="p">}</span>
	
    <span class="c1">//RESNET input shape (BATCH_SIZE, 3, 224, 224)</span>
    <span class="k">const</span> <span class="kt">int</span> <span class="n">BATCH_SIZE</span> <span class="o">=</span> <span class="mi">8</span><span class="p">,</span> <span class="n">CHANNELS</span> <span class="o">=</span> <span class="mi">3</span><span class="p">,</span> <span class="n">HEIGHT</span> <span class="o">=</span> <span class="mi">224</span><span class="p">,</span> <span class="n">WIDTH</span> <span class="o">=</span> <span class="mi">224</span><span class="p">;</span> 

    <span class="n">torch</span><span class="o">::</span><span class="n">NoGradGuard</span> <span class="n">no_grad</span><span class="p">;</span>
    <span class="c1">// Create a vector of inputs.</span>
    <span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">torch</span><span class="o">::</span><span class="n">jit</span><span class="o">::</span><span class="n">IValue</span><span class="o">&gt;</span> <span class="n">inputs</span><span class="p">;</span>
    <span class="n">inputs</span><span class="p">.</span><span class="n">emplace_back</span><span class="p">(</span><span class="n">torch</span><span class="o">::</span><span class="n">ones</span><span class="p">({</span><span class="n">BATCH_SIZE</span><span class="p">,</span> <span class="n">CHANNELS</span><span class="p">,</span> <span class="n">HEIGHT</span><span class="p">,</span> <span class="n">WIDTH</span><span class="p">}));</span>

    <span class="c1">// Execute the model and turn its output into a tensor.</span>
    <span class="k">auto</span> <span class="n">output</span> <span class="o">=</span> <span class="n">module</span><span class="p">.</span><span class="n">forward</span><span class="p">(</span><span class="n">inputs</span><span class="p">).</span><span class="n">toTensor</span><span class="p">();</span>
    <span class="k">for</span> <span class="p">(</span><span class="kt">int</span> <span class="n">i</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="n">BATCH_SIZE</span><span class="p">;</span> <span class="o">++</span><span class="n">i</span><span class="p">)</span> <span class="p">{</span>
        <span class="n">std</span><span class="o">::</span><span class="n">cout</span> <span class="o">&lt;&lt;</span> <span class="n">i</span> <span class="o">&lt;&lt;</span> <span class="s">"th element class: "</span> <span class="o">&lt;&lt;</span> <span class="n">torch</span><span class="o">::</span><span class="n">argmax</span><span class="p">(</span><span class="n">output</span><span class="p">.</span><span class="n">data</span><span class="p">()[</span><span class="n">i</span><span class="p">]).</span><span class="n">item</span><span class="o">&lt;</span><span class="kt">long</span><span class="o">&gt;</span><span class="p">()</span> <span class="o">&lt;&lt;</span> <span class="s">"</span><span class="se">\n</span><span class="s">"</span><span class="p">;</span>
    <span class="p">}</span>
	<span class="k">return</span> <span class="mi">0</span><span class="p">;</span>
<span class="p">}</span>
</code></pre></div></div>

<p>Bu kodu derleyip çalıştıralım ve arkasından kodu inceleyelim:</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>./infer ./model_zoo/resnet152_sc.pt
Module loaded successfully.
Class of 0th element: 600
Class of 1th element: 600
Class of 2th element: 600
Class of 3th element: 600
Class of 4th element: 600
</code></pre></div></div>

<p>Kodu en baştan inceleyecek olursak ilk olarak <code class="language-plaintext highlighter-rouge">torch/script.h</code> başlık dosyasını kodumuza dahil etmemiz yeterli olacaktır. Ardından <code class="language-plaintext highlighter-rouge">torch::jit::script::Module</code> sınıfının bir örneğini oluşturuyoruz. Bu aslında <em>Python</em> da kullandığımız <code class="language-plaintext highlighter-rouge">torch.nn.Module</code> sınıfıdır. Sonuç olarak model nesnesini taşır ve <em>Python</em> API’ın sağladığı özellikleri kullanmamızı sağlar:</p>

<div class="language-c++ highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">torch</span><span class="o">::</span><span class="n">jit</span><span class="o">::</span><span class="n">script</span><span class="o">::</span><span class="n">Module</span> <span class="n">module</span><span class="p">;</span>
</code></pre></div></div>

<p>Ardından daha önce <em>Python</em>‘da kaydettiğimiz modelleri dosyadan okuyup bu nesneye aktarıyoruz. Kaydedilen modeli komut satırından argüman olarak alıp modeli okuyoruz ve hata yakalama mekanizmasını kullanıyoruz:</p>

<div class="language-c++ highlighter-rouge"><div class="highlight"><pre class="highlight"><code>    <span class="k">try</span> <span class="p">{</span>
        <span class="c1">// Deserialize the ScriptModule from a file.</span>
        <span class="n">module</span> <span class="o">=</span> <span class="n">torch</span><span class="o">::</span><span class="n">jit</span><span class="o">::</span><span class="n">load</span><span class="p">(</span><span class="n">argv</span><span class="p">[</span><span class="mi">1</span><span class="p">]);</span>
        <span class="n">std</span><span class="o">::</span><span class="n">cout</span> <span class="o">&lt;&lt;</span> <span class="s">"Module loaded successfully.</span><span class="se">\n</span><span class="s">"</span><span class="p">;</span>
    <span class="p">}</span>
    <span class="k">catch</span> <span class="p">(</span><span class="k">const</span> <span class="n">c10</span><span class="o">::</span><span class="n">Error</span><span class="o">&amp;</span> <span class="n">e</span><span class="p">)</span> <span class="p">{</span>
        <span class="n">std</span><span class="o">::</span><span class="n">cerr</span> <span class="o">&lt;&lt;</span> <span class="s">"Error loading the model.</span><span class="se">\n</span><span class="s">"</span><span class="p">;</span>
        <span class="k">return</span> <span class="o">-</span><span class="mi">1</span><span class="p">;</span>
    <span class="p">}</span>
</code></pre></div></div>

<p>Burada model CPU üzerinde çalışacak şekilde kullanıyoruz. GPU kullanmak isterseniz aşağıdaki kodu modeli yüklediğiniz satırdan sonraki satıra eklemeniz yeterli olacaktır:</p>

<div class="language-c++ highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">module</span><span class="p">.</span><span class="n">to</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">kCUDA</span><span class="p">);</span>
</code></pre></div></div>

<p>Girdilerimizi modele beslemek için ihtiyacımız olan vektörü hazırlayacağız. <code class="language-plaintext highlighter-rouge">torch::jit::script::Module</code> sınıfının <code class="language-plaintext highlighter-rouge">forward</code> fonksiyonu bizden <code class="language-plaintext highlighter-rouge">std::vector&lt;torch::jit::IValue&gt;</code> türünden bir vektör bekliyor. Fonksiyon argümanı olan vektörü <code class="language-plaintext highlighter-rouge">std::move()</code> ile taşıma semantiğine uygun olarak kullandığından bellek kullanımı ve hız kaybını olası en düşük hale getirmeyi amaçladığını hatırlatmak isterim:</p>

<div class="language-c++ highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">torch</span><span class="o">::</span><span class="n">jit</span><span class="o">::</span><span class="n">IValue</span><span class="o">&gt;</span> <span class="n">inputs</span><span class="p">;</span>
<span class="n">inputs</span><span class="p">.</span><span class="n">push_back</span><span class="p">(</span><span class="n">torch</span><span class="o">::</span><span class="n">ones</span><span class="p">({</span><span class="n">BATCH_SIZE</span><span class="p">,</span> <span class="n">CHANNELS</span><span class="p">,</span> <span class="n">HEIGHT</span><span class="p">,</span> <span class="n">WIDTH</span><span class="p">}));</span>
<span class="c1">//for GPU tensors:</span>
<span class="c1">//inputs.push_back(torch::ones({BATCH_SIZE, CHANNELS, HEIGHT, WIDTH}).to(at::kCUDA));</span>
</code></pre></div></div>

<p><code class="language-plaintext highlighter-rouge">torch::jit::IValue</code> bir sınıf olarak tanımlanmıştır. <em>Interpreter Value</em>‘nun kısaltması olarak <code class="language-plaintext highlighter-rouge">IValue</code> sınıfı <em>TorchScript interpreter</em> tarafından desteklenen tüm temel türleri sarmalamaktadır. <code class="language-plaintext highlighter-rouge">IValue</code> sınıfı modellere girdi ve çıktılar için kullanılır. Bu sınıfın arayüzü oldukça geniş olmasına rağmen temel iki fonksiyonu için aşağıya bakabilirsiniz:</p>

<div class="language-c++ highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">///   // Make the IValue</span>
<span class="n">torch</span><span class="o">::</span><span class="n">IValue</span> <span class="nf">my_ivalue</span><span class="p">(</span><span class="mi">26</span><span class="p">);</span>
<span class="n">std</span><span class="o">::</span><span class="n">cout</span> <span class="o">&lt;&lt;</span> <span class="n">my_ivalue</span> <span class="o">&lt;&lt;</span> <span class="s">"</span><span class="se">\n</span><span class="s">"</span><span class="p">;</span>
<span class="c1">///</span>
<span class="c1">///   // Unwrap the IValue</span>
<span class="kt">int64_t</span> <span class="n">my_int</span> <span class="o">=</span> <span class="n">my_ivalue</span><span class="p">.</span><span class="n">toInt</span><span class="p">()</span> <span class="c1">//toX() instead of X use appropriate data type for wrapped data.</span>
<span class="n">std</span><span class="o">::</span><span class="n">cout</span> <span class="o">&lt;&lt;</span> <span class="n">my_int</span> <span class="o">&lt;&lt;</span> <span class="s">"</span><span class="se">\n</span><span class="s">"</span><span class="p">;</span>
</code></pre></div></div>

<p>Bu noktada neden böyle bir sınıfa ihtiyaç duyulduğuna gelecek olursak <em>C++</em> tarafından sağlanan temel türlerden farklı olarak <em>LibTorch</em>‘un sağladığı türler farklıdır. <em>Python</em> API ile <em>C++</em> API arasında uyumu sağlamaya yardımcı olduğundan öğrenme/kullanma/alışmayı kolaylaştırmaktadır.</p>

<p>Artık son olarak modele girdileri besleyip çıktıda yığındaki (batch) her bir eleman en olası sınıfı standart çıktıya yazdırıyoruz:</p>

<div class="language-c++ highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">auto</span> <span class="n">output</span> <span class="o">=</span> <span class="n">module</span><span class="p">.</span><span class="n">forward</span><span class="p">(</span><span class="n">inputs</span><span class="p">).</span><span class="n">toTensor</span><span class="p">();</span>
<span class="k">for</span> <span class="p">(</span><span class="kt">int</span> <span class="n">i</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="n">BATCH_SIZE</span><span class="p">;</span> <span class="o">++</span><span class="n">i</span><span class="p">)</span> <span class="p">{</span>
    <span class="n">std</span><span class="o">::</span><span class="n">cout</span> <span class="o">&lt;&lt;</span> <span class="s">"Class of "</span> <span class="o">&lt;&lt;</span> <span class="n">i</span> <span class="o">&lt;&lt;</span> <span class="s">"th element: "</span> <span class="o">&lt;&lt;</span> <span class="n">torch</span><span class="o">::</span><span class="n">argmax</span><span class="p">(</span><span class="n">output</span><span class="p">.</span><span class="n">data</span><span class="p">()[</span><span class="n">i</span><span class="p">]).</span><span class="n">item</span><span class="o">&lt;</span><span class="kt">long</span><span class="o">&gt;</span><span class="p">()</span> <span class="o">&lt;&lt;</span> <span class="s">"</span><span class="se">\n</span><span class="s">"</span><span class="p">;</span>
<span class="p">}</span>
</code></pre></div></div>

<p>Bu noktada bir karşılaştırma yapmakta fayda olacaktır. Bunun için Python’da <code class="language-plaintext highlighter-rouge">jit</code> modülünü kullanmadan, <code class="language-plaintext highlighter-rouge">script</code> ve <code class="language-plaintext highlighter-rouge">trace</code> modunda farklı yığın boyutları için CPU ve GPU’da kaydedilen modeli okuma ve çalışma süreleriyle bu işlemlerin C++’da yaptığımızda elde edeceğimiz süreleri (tüm testler 10 defa çalıştırılıp süre ortalama olarak hesaplanmıştır) karşılaştıracağız. İlk olarak kaydedilen model dosyalarının boyutlarına bakalım. Dosya boyutları arasında anlamlı bir fark bulunmadığını söyleyebiliriz:</p>

<table>
  <thead>
    <tr>
      <th>Modül Tipi</th>
      <th>Dosya Boyutu</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>torch.nn.Module</td>
      <td>241.6 MB</td>
    </tr>
    <tr>
      <td>torch.jit.script</td>
      <td>242 MB</td>
    </tr>
    <tr>
      <td>torch.jit.trace</td>
      <td>242.2 MB</td>
    </tr>
  </tbody>
</table>

<p>Şimdi model dosyalarının diskten okunup CPU üzerinde modelin çalıştırılabilir hale getirilmesi için geçen süreye bakalım. Görüldüğü üzere öncelikle okumayı C++’da çok daha hızlı yapabiliyoruz:</p>

<table>
  <thead>
    <tr>
      <th>CPU Okuma zamanı (ms)</th>
      <th>Python</th>
      <th>C++</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>Script</td>
      <td>0.985</td>
      <td>0.449</td>
    </tr>
    <tr>
      <td>Trace</td>
      <td>0.912</td>
      <td>0.356</td>
    </tr>
  </tbody>
</table>

<p>Şimdi de model dosyasının okunması ve GPU üzerinde çalıştırılabilir hale getirilmesi için geçen süreye bakalım. Hız farkı azalsa da <em>C++</em> hala daha hızlı okuyor ve modeli çalıştırılabilir hale getiriyor:</p>

<table>
  <thead>
    <tr>
      <th>GPU Okuma zamanı (ms)</th>
      <th>Python</th>
      <th>C++</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>Script</td>
      <td>2.286</td>
      <td>2.137</td>
    </tr>
    <tr>
      <td>Trace</td>
      <td>2.214</td>
      <td>2.025</td>
    </tr>
  </tbody>
</table>

<p>Artık yığın işleme sürelerini inceleyelim. Soldaki çizgede CPU, sağdaki çizgedeyse GPU üzerinde farklı yığın boyutlarında bir örnek için modelin çıkarım süreleri görülmektedir. Test durumlarının %95’inde değişen oranlarda <em>C++</em> API’ı daha hızlı çalışmaktadır. CPU üzerinde genelde <code class="language-plaintext highlighter-rouge">script</code> modunda kaydedilen modeller, GPU tarafındaysa <code class="language-plaintext highlighter-rouge">trace</code> modunda kaydedilen modeller daha hızlı çalışmışlardır. Bu hesaplamalarda tek işlem/iş parçacığı kullanılmıştır:</p>

<p><img src="/assets/img/libtorch_infer/cpu_gpu.png" alt="" /></p>

<p>Sonuç olarak aslında <em>C++ API</em> kullanarak modelleri çalıştırmanın hiç de zahmetli olmadığını gördüğünüzü düşünüyorum. Aslında sıfırdan bir modeli <em>C++</em> üzerinde geliştirmekte çok zor değil. Sonraki yazılarda bunu da açıklamaya çalışacağım. Ama öncelikle verilerle nasıl başa çıkacağımızı incelemenin daha iyi olacağını düşünüyorum. Sonraki yazıda verileri (resim, video, csv, metin vb.) okumayı ve <em>LibTorch</em>‘a çıkarım ve eğitim sırasında bu verileri nasıl sağlayacağımızı açıklayacağım.</p>

<p><em>Dizinin diğer yazıları:</em></p>

<ol>
  <li>
    <p><a href="https://blgnksy.github.io/tr/2020/12/03/libtorch-config.html">C++ Derin Öğrenme-1 Pytorch C++ API LibTorch Giriş</a></p>
  </li>
  <li>
    <p><a href="https://blgnksy.github.io/tr/2020/12/06/libtorch-tensors.html">C++ Derin Öğrenme-2 Pytorch C++ API LibTorch Tensör İşlemleri</a></p>
  </li>
</ol>

</section>
   
   <!-- Tag list -->
  
  


<footer>
  <div class="tag-list">
    
      <div class="meta">Tags</div>
    

    
    <a class="button" href="/tags#Deep Learning">
      <p><i class="fa fa-tag fa-fw"></i> Deep Learning</p>
    </a>
    
    <a class="button" href="/tags#Deep Learning C++">
      <p><i class="fa fa-tag fa-fw"></i> Deep Learning C++</p>
    </a>
    
    <a class="button" href="/tags#Derin Öğrenme">
      <p><i class="fa fa-tag fa-fw"></i> Derin Öğrenme</p>
    </a>
    
    <a class="button" href="/tr/tags#Inference">
      <p><i class="fa fa-tag fa-fw"></i> Inference</p>
    </a>
    
    <a class="button" href="/tr/tags#LibTorch">
      <p><i class="fa fa-tag fa-fw"></i> LibTorch</p>
    </a>
    
    <a class="button" href="/tags#Machine Learning">
      <p><i class="fa fa-tag fa-fw"></i> Machine Learning</p>
    </a>
    
    <a class="button" href="/tags#Machine Learning C++">
      <p><i class="fa fa-tag fa-fw"></i> Machine Learning C++</p>
    </a>
    
    <a class="button" href="/tags#Makine Öğrenmesi">
      <p><i class="fa fa-tag fa-fw"></i> Makine Öğrenmesi</p>
    </a>
    
    <a class="button" href="/tr/tags#PyTorch">
      <p><i class="fa fa-tag fa-fw"></i> PyTorch</p>
    </a>
    
    <a class="button" href="/tags#PyTorch C++ API">
      <p><i class="fa fa-tag fa-fw"></i> PyTorch C++ API</p>
    </a>
    
    <a class="button" href="/tr/tags#Çıkarım">
      <p><i class="fa fa-tag fa-fw"></i> Çıkarım</p>
    </a>
    
  </div>
</footer>

    
  <!-- Structured Data for Blog Post -->
  <script type="application/ld+json">
  {
    "@context": "https://schema.org",
    "@type": "BlogPosting",
    "headline": "C++ Derin Öğrenme-3 Pytorch C++ API LibTorch Modelleri Çalıştırma",
    "author": {
      "@type": "Person",
      "name": ""
    },
    "datePublished": "2020-12-13T00:00:00+00:00",
    "dateModified": "2020-12-13T00:00:00+00:00",
    "mainEntityOfPage": {
      "@type": "WebPage",
      "@id": "https://blgnksy.github.io/2020/12/13/libtorch-inference.html"
    },
    "publisher": {
      "@type": "Organization",
      "name": "NDeep",
      "logo": {
        "@type": "ImageObject",
        "url": "https://blgnksy.github.io/assets/favicon.ico"
      }
    },
    "image": "https://blgnksy.github.io",
    "articleSection": "",
    "keywords": "Deep Learning, Derin Öğrenme, PyTorch, LibTorch, PyTorch C++ API, Machine Learning C++, Deep Learning C++, Machine Learning, Makine Öğrenmesi, Inference, Çıkarım",
    "inLanguage": "tr"
  }
  </script>
    
</article>

<!-- Disqus -->

<div id="disqus_thread"></div>
    <script type="text/javascript">
        /* * * CONFIGURATION VARIABLES: EDIT BEFORE PASTING INTO YOUR WEBPAGE * * */
        var disqus_shortname = 'https-blgnksy-github-io'; // required: replace example with your forum shortname
        /*var disqus_developer = 1; // Comment out when the site is live*/
        var disqus_identifier = "/2020/12/13/libtorch-inference.html";

        /* * * DON'T EDIT BELOW THIS LINE * * */
        (function() {
            var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
            dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
            (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
        })();
    </script>
    <noscript>Please enable JavaScript to view the <a href="http://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
    <a href="http://disqus.com" class="dsq-brlink">comments powered by <span class="logo-disqus">Disqus</span></a>




<!-- Post navigation -->

  <div id="post-nav">
  
  <div id="previous-post" class="post-nav-post">
      <p>Previous post</p>
      <a href="/tr/2020/12/06/libtorch-tensors.html">
        C++ Derin Öğrenme-2 Pytorch C++ API LibTorch Tensör İşlemleri
      </a>
  </div>
  
  
  <div id="next-post" class="post-nav-post">
      <p>Next post</p>
      <a href="/tr/2025/12/22/minimal-os.html">
        Minimalist OS
      </a>
  </div>
  
</div>


    </div>
    
<footer class="site-footer">
    <p class="text">Powered by <a href="https://jekyllrb.com/">Jekyll</a> with <a href="https://github.com/sylhare/Type-on-Strap">Type on Strap</a>
</p>
            <div class="footer-icons">
                <ul>
                <!-- Social icons from Font Awesome, if enabled -->
                


<li>
	<a href="mailto:bilgin.aksoy@metu.edu.tr" title="Email">
		<span class="fa-stack fa-lg">
            <i class="fa fa-circle fa-stack-2x"></i>
            <i class="fa fa-envelope fa-stack-1x fa-inverse"></i>
        </span>
	</a>
</li>





<li>
	<a href="https://bitbucket.org/blgnksy" title="Follow on Bitbucket">
		<span class="fa-stack fa-lg">
            <i class="fa fa-circle fa-stack-2x"></i>
            <i class="fa fa-bitbucket fa-stack-1x fa-inverse"></i>
        </span>
	</a>
</li>









<li>
	<a href="https://github.com/blgnksy" title="Follow on GitHub">
		<span class="fa-stack fa-lg">
            <i class="fa fa-circle fa-stack-2x"></i>
            <i class="fa fa-github fa-stack-1x fa-inverse"></i>
        </span>
	</a>
</li>









<li>
	<a href="https://www.linkedin.com/in/bilgin-aksoy-a61a90110" title="Follow on LinkedIn">
		<span class="fa-stack fa-lg">
            <i class="fa fa-circle fa-stack-2x"></i>
            <i class="fa fa-linkedin fa-stack-1x fa-inverse"></i>
        </span>
	</a>
</li>

















<li>
	<a href="https://twitter.com/blgnksy" title="Follow on Twitter" class="type">
        <span class="fa-stack fa-lg">
            <i class="fa fa-circle fa-stack-2x"></i>
            <i class="fa fa-twitter fa-stack-1x fa-inverse"></i>
        </span>
	</a>
</li>








                </ul>
            </div>
</footer>




  </body>
</html>
<script type="text/javascript">
      /* * * CONFIGURATION VARIABLES: EDIT BEFORE PASTING INTO YOUR WEBPAGE * * */
      var disqus_shortname = 'https-blgnksy-github-io'; // required: replace example with your forum shortname
      //var disqus_developer = 1; // Comment out when the site is live

      /* * * DON'T EDIT BELOW THIS LINE * * */
      (function () {
        var s = document.createElement('script'); s.async = true;
        s.type = 'text/javascript';
        s.src = 'http://' + disqus_shortname + '.disqus.com/count.js';
        (document.getElementsByTagName('HEAD')[0] || document.getElementsByTagName('BODY')[0]).appendChild(s);
      }());
    </script>
